{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11322ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "Test = pickle.load(open(r\"C:\\Users\\Admin\\Documents\\GitHub\\DD-Net-Pytorch\\data\\JHMDB\\GT_test_1.pkl\", \"rb\"))\n",
    "Train = pickle.load(open(r\"C:\\Users\\Admin\\Documents\\GitHub\\DD-Net-Pytorch\\data\\JHMDB\\GT_train_1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f88027c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 15, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train['pose'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b642625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clap'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bc18c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uiprmd_train = pickle.load(open(r\"C:\\Users\\Admin\\Documents\\GitHub\\DD-Net-Pytorch\\UIPRMD_pickle\\EX_2\\train_dataset.pkl\", \"rb\"))\n",
    "uiprmd_test = pickle.load(open(r\"C:\\Users\\Admin\\Documents\\GitHub\\DD-Net-Pytorch\\UIPRMD_pickle\\EX_2\\test_dataset.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0441af1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pose', 'labels'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uiprmd_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6aafec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 194, 39, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uiprmd_train['pose'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec1b0992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([194, 39, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uiprmd_train['pose'][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "641ca83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6286])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uiprmd_train['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2ae6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "lb = np.copy(uiprmd_train['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a7e4181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62861], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6680af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, dim // 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class ODEBlock(nn.Module):\n",
    "    def __init__(self, odefunc, tol=1e-3):\n",
    "        super().__init__()\n",
    "        self.odefunc = odefunc\n",
    "        self.tol = tol\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, D)\n",
    "        B, T, D = x.shape\n",
    "        x = x.reshape(B * T, D)\n",
    "        t = torch.tensor([0, 1]).float().to(x.device)\n",
    "        out = odeint(self.odefunc, x, t, rtol=self.tol, atol=self.tol)\n",
    "        out = out[1]\n",
    "        out = out.view(B, T, D)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ad947f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 16, 64])\n",
      "Input shape: torch.Size([32, 32, 30])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding:utf-8\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "\n",
    "class c1D(nn.Module):\n",
    "    # input (B,C,D) //batch,channels,dims\n",
    "    # output = (B,C,filters)\n",
    "    def __init__(self, input_channels, input_dims, filters, kernel):\n",
    "        super(c1D, self).__init__()\n",
    "        self.cut_last_element = (kernel % 2 == 0)\n",
    "        self.padding = math.ceil((kernel - 1)/2)\n",
    "        self.conv1 = nn.Conv1d(input_dims, filters,\n",
    "                               kernel, bias=False, padding=self.padding)\n",
    "        self.bn = nn.BatchNorm1d(num_features=input_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (B,D,C)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # output (B,filters,C)\n",
    "        if self.cut_last_element:\n",
    "            output = self.conv1(x)[:, :, :-1]\n",
    "        else:\n",
    "            output = self.conv1(x)\n",
    "        # output = (B,C,filters)\n",
    "        output = output.permute(0, 2, 1)\n",
    "        output = self.bn(output)\n",
    "        output = F.leaky_relu(output, 0.2, inplace=True)\n",
    "        return output\n",
    "\n",
    "\n",
    "class spatialDropout1D(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super(spatialDropout1D, self).__init__()\n",
    "        self.dropout = nn.Dropout1d(p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, channels, filters):\n",
    "        super(ODEFunc, self).__init__()\n",
    "        self.filters = filters\n",
    "        # Use c1D to mimic convolutional dynamics\n",
    "        self.conv = c1D(channels, filters, filters, 3) \n",
    "        self.norm = nn.LayerNorm(filters)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        # x: (B, frame_l, filters)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        return torch.relu(x)\n",
    "\n",
    "\n",
    "class SlowODE(nn.Module):\n",
    "    def __init__(self, frame_l, joint_n, joint_d, filters):\n",
    "        super(SlowODE, self).__init__()\n",
    "        self.frame_l = frame_l\n",
    "        self.joint_n = joint_n\n",
    "        self.joint_d = joint_d\n",
    "        self.filters = filters\n",
    "\n",
    "        # Initial transformation to match filters\n",
    "        self.init_conv = nn.Sequential(\n",
    "            c1D(frame_l, joint_n * joint_d, filters, 1),\n",
    "            spatialDropout1D(0.1)\n",
    "        )\n",
    "\n",
    "        # ODE block\n",
    "        self.ode_func = ODEFunc(frame_l, filters)\n",
    "        self.ode_dropout = spatialDropout1D(0.1)\n",
    "\n",
    "        # Pooling to reduce temporal dimension\n",
    "        self.pool = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            spatialDropout1D(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, frame_l, joint_n * joint_d)\n",
    "        B, frame_l, _ = x.shape\n",
    "        if frame_l != self.frame_l:\n",
    "            raise ValueError(f\"Input frame_l mismatch: expected {self.frame_l}, got {frame_l}\")\n",
    "\n",
    "        # Initial transformation\n",
    "        x = self.init_conv(x)  # (B, frame_l, filters)\n",
    "        \n",
    "        # ODE integration\n",
    "        t_span = torch.linspace(0, 1, 5, device=x.device)\n",
    "        # x = odeint(self.ode_func, x, t_span, method='rk4')[-1]  # (B, frame_l, filters)\n",
    "        x = odeint(self.ode_func, x, t_span, method='dopri5')[-1]\n",
    "        x = self.ode_dropout(x)\n",
    "\n",
    "        # Pooling\n",
    "        x = x.permute(0, 2, 1)  # (B, filters, frame_l)\n",
    "        x = self.pool(x)  # (B, filters, frame_l//2)\n",
    "        x = x.permute(0, 2, 1)  # (B, frame_l//2, filters)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    frame_l, joint_n, joint_d, filters = 32, 15, 2, 64\n",
    "    model = SlowODE(frame_l, joint_n, joint_d, filters).to(device)\n",
    "    x = torch.randn(32, frame_l, joint_n * joint_d).to(device)  # Batch of 2\n",
    "    output = model(x)\n",
    "    print(\"Output shape:\", output.shape)  # Expected: (2, 32, 64)\n",
    "    print(\"Input shape:\", x.shape)  # Expected: (2, 32, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55ef156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([8, 64, 32, 32])\n",
      "Output shape:  torch.Size([8, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from models.ulsam import ULSAM\n",
    "# Giả sử input có 64 channels, kích thước 32x32\n",
    "nin = 64\n",
    "nout = 64  # thông thường bằng nin, vì ULSAM không thay đổi số channels\n",
    "h, w = 32, 32\n",
    "num_splits = 4\n",
    "\n",
    "# Tạo mô-đun\n",
    "ulsam = ULSAM(nin=nin, nout=nout, h=h, w=w, num_splits=num_splits).cuda()\n",
    "\n",
    "# Tạo đầu vào giả (batch_size=8)\n",
    "x = torch.randn(8, nin, h, w).cuda()\n",
    "\n",
    "# Forward\n",
    "out = ulsam(x)\n",
    "\n",
    "print(\"Input shape: \", x.shape)\n",
    "print(\"Output shape: \", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simam_module(torch.nn.Module):\n",
    "    def __init__(self, channels = None, e_lambda = 1e-4):\n",
    "        super(simam_module, self).__init__()\n",
    "\n",
    "        self.activaton = nn.Sigmoid()\n",
    "        self.e_lambda = e_lambda\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = self.__class__.__name__ + '('\n",
    "        s += ('lambda=%f)' % self.e_lambda)\n",
    "        return s\n",
    "\n",
    "    @staticmethod\n",
    "    def get_module_name():\n",
    "        return \"simam\"\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        b, c, h, w = x.size()\n",
    "        \n",
    "        n = w * h - 1\n",
    "\n",
    "        x_minus_mu_square = (x - x.mean(dim=[2,3], keepdim=True)).pow(2)\n",
    "        y = x_minus_mu_square / (4 * (x_minus_mu_square.sum(dim=[2,3], keepdim=True) / n + self.e_lambda)) + 0.5\n",
    "\n",
    "        return x * self.activaton(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e5ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Định nghĩa simam_module\n",
    "class simam_module(nn.Module):\n",
    "    def __init__(self, e_lambda=1e-4):\n",
    "        super(simam_module, self).__init__()\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.e_lambda = e_lambda\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        n = w * h - 1\n",
    "        x_minus_mu_square = (x - x.mean(dim=[2, 3], keepdim=True)).pow(2)\n",
    "        y = x_minus_mu_square / (4 * (x_minus_mu_square.sum(dim=[2, 3], keepdim=True) / n + self.e_lambda)) + 0.5\n",
    "        return x * self.activation(y)\n",
    "\n",
    "class EleAttG_GRU_SimAM(nn.Module):\n",
    "    def __init__(self, embedding_dim, n_hidden=128, n_classes=None):\n",
    "        super(EleAttG_GRU_SimAM, self).__init__()\n",
    "\n",
    "        assert n_classes is not None\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.attention = simam_module(e_lambda=1e-4)\n",
    "        self.grucell = nn.GRUCell(self.embedding_dim, self.n_hidden)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.n_hidden, self.n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.n_hidden, self.n_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X: [batch_size, frames, embedding_dim]\n",
    "        \"\"\"\n",
    "        h = torch.zeros(X.shape[0], self.n_hidden).to(X.device)\n",
    "\n",
    "        X = X.permute(0, 2, 1).unsqueeze(-1)  # [batch, embedding_dim, frames, 1]\n",
    "        X = self.attention(X)  # [batch, embedding_dim, frames, 1]\n",
    "        X = X.squeeze(-1).permute(0, 2, 1)  # [batch, frames, embedding_dim]\n",
    "\n",
    "        for i in range(X.shape[1]):\n",
    "            h = self.grucell(X[:, i, :], h)\n",
    "\n",
    "        return self.fc(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7a3b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 5])\n",
      "Output: tensor([[0.2065, 0.2216, 0.2010, 0.1862, 0.1848],\n",
      "        [0.1990, 0.2119, 0.2008, 0.1953, 0.1930],\n",
      "        [0.1985, 0.2211, 0.2068, 0.1849, 0.1887],\n",
      "        [0.1930, 0.2227, 0.1976, 0.1919, 0.1948]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    batch_size = 4\n",
    "    seq_len = 10  # số lượng frames\n",
    "    embedding_dim = 32\n",
    "    n_hidden = 64\n",
    "    n_classes = 5\n",
    "\n",
    "    # Tạo dữ liệu giả\n",
    "    X_fake = torch.randn(batch_size, seq_len, embedding_dim)\n",
    "\n",
    "    # Khởi tạo model\n",
    "    model = EleAttG_GRU_SimAM(embedding_dim=embedding_dim, n_hidden=n_hidden, n_classes=n_classes)\n",
    "\n",
    "    # Chạy forward\n",
    "    output = model(X_fake)\n",
    "\n",
    "    # In output\n",
    "    print(\"Output shape:\", output.shape)  # Expect: [batch_size, n_classes]\n",
    "    print(\"Output:\", output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
